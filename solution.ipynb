{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14ac0010",
   "metadata": {},
   "source": [
    "# Using Ultralytics YOLOv8, ByteTrack and Supervision for tracking and counting \n",
    "\n",
    "\n",
    "\n",
    "    Detection with yolov8\n",
    "    \n",
    "    Tracking with BoT-SORT \n",
    "    \n",
    "    Counting using supervision\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c57616e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8.0.106'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install ultralytics\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf85fdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supervision.__version__: 0.14.0\n"
     ]
    }
   ],
   "source": [
    "import supervision\n",
    "print(\"supervision.__version__:\", supervision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8921b036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cu117'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e215c39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3090'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736ee096",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1257d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLOv8n model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Run inference on 'bus.jpg' with arguments\n",
    "model.predict(source=\"testing/d.mp4\", save=True, imgsz=320, conf=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c383feaf",
   "metadata": {},
   "source": [
    "# Tracking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "358a6175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Configure the tracking parameters and run the tracker\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "results = model.track(source=\"testing/d.mp4\",conf=0.3, iou=0.5, save=True, tracker=\"bytetrack.yaml\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc7bc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9688638",
   "metadata": {},
   "source": [
    "# Tracking and counting  - 1 line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0db56170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from collections import defaultdict\n",
    "import supervision as sv\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Set up video capture\n",
    "cap = cv2.VideoCapture(\"testing/d.mp4\")\n",
    "\n",
    "# Define the line coordinates\n",
    "START = sv.Point(182, 254)\n",
    "END = sv.Point(462, 254)\n",
    "\n",
    "\n",
    "# Store the track history\n",
    "track_history = defaultdict(lambda: [])\n",
    "\n",
    "# Create a dictionary to keep track of objects that have crossed the line\n",
    "crossed_objects = {}\n",
    "\n",
    "# Open a video sink for the output video\n",
    "video_info = sv.VideoInfo.from_video_path(\"testing/d.mp4\")\n",
    "with sv.VideoSink(\"output_single_line.mp4\", video_info) as sink:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "\n",
    "        if success:\n",
    "            # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
    "            results = model.track(frame, classes=[2, 3, 5, 7], persist=True, save=True, tracker=\"bytetrack.yaml\")\n",
    "\n",
    "            # Get the boxes and track IDs\n",
    "            boxes = results[0].boxes.xywh.cpu()\n",
    "            track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "\n",
    "            # Visualize the results on the frame\n",
    "            annotated_frame = results[0].plot()\n",
    "            detections = sv.Detections.from_yolov8(results[0])\n",
    "\n",
    "            # Plot the tracks and count objects crossing the line\n",
    "            for box, track_id in zip(boxes, track_ids):\n",
    "                x, y, w, h = box\n",
    "                track = track_history[track_id]\n",
    "                track.append((float(x), float(y)))  # x, y center point\n",
    "                if len(track) > 30:  # retain 30 tracks for 30 frames\n",
    "                    track.pop(0)\n",
    "\n",
    "                # Check if the object crosses the line\n",
    "                if START.x < x < END.x and abs(y - START.y) < 5:  # Assuming objects cross horizontally\n",
    "                    if track_id not in crossed_objects:\n",
    "                        crossed_objects[track_id] = True\n",
    "\n",
    "                    # Annotate the object as it crosses the line\n",
    "                    cv2.rectangle(annotated_frame, (int(x - w / 2), int(y - h / 2)), (int(x + w / 2), int(y + h / 2)), (0, 255, 0), 2)\n",
    "\n",
    "            # Draw the line on the frame\n",
    "            cv2.line(annotated_frame, (START.x, START.y), (END.x, END.y), (0, 255, 0), 2)\n",
    "\n",
    "            # Write the count of objects on each frame\n",
    "            count_text = f\"Objects crossed: {len(crossed_objects)}\"\n",
    "            cv2.putText(annotated_frame, count_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            # Write the frame with annotations to the output video\n",
    "            sink.write_frame(annotated_frame)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "# Release the video capture\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9c80bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
